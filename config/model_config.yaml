
# Local model config for video analysis
local_model:
  prompt_file: "video_understanding_en.md"
  max_tokens: 1024
  temperature: 0.7
  fps: 2.0
  max_frames: 16

# lower number means higher priority
provider_priorities:
  siliconflow: 2
  deepseek_call: 4
  github_call: 5
  azure_call: 3 
  qwen_call: 1